# 海量数据处理



## 1. 海量数据，怎么统计出字符串出现的个数?（假设1000G数据，只有4G内存大小)



## 2. 百亿数量级 URL 求交集

### 题目描述

有两个文件 file1 和 file2，各自记录了很多 URL：

*   URL 每行一个，长度不超过 200 字节，数量各自在百亿级别；
*   一个 URL 在同个文件中可能多次出现

要求：读取并计算两个文件所包含的 URL 集合的交集，即同时出现在二者中的 URL 集合，结果写入文件 file3：

*   结果集合需要对 URL 去重，即每个 URL 只出现一次；
*   输出格式：每行一个 URL
*   使用标准库的函数或类实现，需要检查错误，出错时直接退出进程即可。

Tips：

*   执行任务的机器内存约 16 GB，相对于设计的数据量是很小的；
*   磁盘空间可认为是无限的
*   需要考虑到性能，要能在可接受的时间内完成处理

来源：影石Insta360 C++工程师 笔试

### 解决方案

#### 解决思路

外部排序 + 归并排序：

1.   分块排序
     *   一次读一块（比如 100 MB）进内存；
     *   `std::sort` 排序后写到临时文件；
     *   最后得到很多个有序的“小文件”。
2.   多路归并
     *   用最小堆同时归并这些小文件；
     *   输出一个全局有序的大文件。
3.   两个有序文件求交集
     *   读 `file1_sorted` 和 `file2_sorted`，像归并排序那样对齐比较；
     *   相等 $\to$ 输出到结果文件（避免重复）。

#### 具体实现

```cpp
#include <iostream>
#include <fstream>
#include <string>
#include <vector>
#include <queue>
#include <algorithm>
#include <cstdio>

// 每次处理的内存块大小（字节）
const size_t CHUNK_SIZE = 100 * 1024 * 1024; // 100MB

// 工具函数：生成临时文件名
std::string tempFileName(int idx, const std::string& prefix) {
    return prefix + "_chunk_" + std::to_string(idx) + ".txt";
}

// 步骤1：分块排序
std::vector<std::string> splitAndSort(const std::string& inputFile, const std::string& prefix) {
    std::ifstream in(inputFile);
    std::vector<std::string> tmpFiles;
    std::vector<std::string> buffer;
    size_t currentSize = 0;
    int fileIdx = 0;
    std::string line;

    while (std::getline(in, line)) {
        currentSize += line.size() + 1;
        buffer.push_back(line);

        if (currentSize >= CHUNK_SIZE) {
            std::sort(buffer.begin(), buffer.end());
            std::string tmp = tempFileName(fileIdx++, prefix);
            std::ofstream out(tmp);
            for (auto& s : buffer) out << s << "\n";
            out.close();
            tmpFiles.push_back(tmp);
            buffer.clear();
            currentSize = 0;
        }
    }

    // 剩余部分
    if (!buffer.empty()) {
        std::sort(buffer.begin(), buffer.end());
        std::string tmp = tempFileName(fileIdx++, prefix);
        std::ofstream out(tmp);
        for (auto& s : buffer) out << s << "\n";
        out.close();
        tmpFiles.push_back(tmp);
    }

    return tmpFiles;
}

// 步骤2：多路归并
void mergeSortedFiles(const std::vector<std::string>& files, const std::string& outputFile) {
    struct Node {
        std::string value;
        int fileIdx;
        bool operator>(const Node& other) const { return value > other.value; }
    };

    std::vector<std::ifstream> streams(files.size());
    for (size_t i = 0; i < files.size(); ++i) {
        streams[i].open(files[i]);
    }

    std::priority_queue<Node, std::vector<Node>, std::greater<Node>> pq;
    for (int i = 0; i < (int)files.size(); ++i) {
        std::string line;
        if (std::getline(streams[i], line)) {
            pq.push({line, i});
        }
    }

    std::ofstream out(outputFile);
    std::string last;
    while (!pq.empty()) {
        auto cur = pq.top(); pq.pop();
        if (cur.value != last) { // 去重
            out << cur.value << "\n";
            last = cur.value;
        }
        std::string next;
        if (std::getline(streams[cur.fileIdx], next)) {
            pq.push({next, cur.fileIdx});
        }
    }

    for (auto& s : streams) s.close();
}

// 步骤3：两个有序文件求交集
void intersectSortedFiles(const std::string& file1, const std::string& file2, const std::string& outFile) {
    std::ifstream f1(file1), f2(file2);
    std::ofstream out(outFile);

    std::string s1, s2, last;
    bool has1 = (bool)std::getline(f1, s1);
    bool has2 = (bool)std::getline(f2, s2);

    while (has1 && has2) {
        if (s1 == s2) {
            if (s1 != last) { // 避免重复
                out << s1 << "\n";
                last = s1;
            }
            has1 = (bool)std::getline(f1, s1);
            has2 = (bool)std::getline(f2, s2);
        } else if (s1 < s2) {
            has1 = (bool)std::getline(f1, s1);
        } else {
            has2 = (bool)std::getline(f2, s2);
        }
    }
}

// 主程序
int main() {
    std::string file1 = "./file1.txt";
    std::string file2 = "./file2.txt";

    // 第一步：对两个大文件分别排序
    auto tmp1 = splitAndSort(file1, "f1");
    auto tmp2 = splitAndSort(file2, "f2");

    // 第二步：合并排序结果
    mergeSortedFiles(tmp1, "file1_sorted.txt");
    mergeSortedFiles(tmp2, "file2_sorted.txt");

    // 第三步：求交集
    intersectSortedFiles("file1_sorted.txt", "file2_sorted.txt", "file3.txt");

    std::cout << "交集已写入 file3.txt\n";
    return 0;
}

```

#### 使用说明

1.   准备两个大文件 `file1.txt`，`file2.txt`。
2.   程序会生成很多临时文件：
     *   `f1_chunk_*.txt`
     *   `f2_chunk_*.txt`
     *   再归并成 `file1_sorted.txt`，`file2_sorted.txt`
3.   最终交集结果在 `file3.txt`

#### 特点

*   **可扩展到百亿级 URL**（取决于磁盘空间和分块大小）；
*   **内存占用固定**，只依赖 `CHUNK_SIZE`；
*   **磁盘 IO 较多**，所以需要 SSD / 并行 IO 优化。





## 参考资料

[1] [海量数据处理面试题](https://interviewguide.cn/notes/03-hunting_job/02-interview/07-01-massive_data.html)